{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"607_HW2_v2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AU5rFXAvEaFR"},"source":["# Note:\n","#### This notebook is Assigment 2, praticing sparkSQL commands based on another program called Covid19_demo2.ipynb file.  Practice that demo program first and then fill in the Spark Commands for the questions that begin with **#Q** (e..g, #Q1, #Q2, #Q3, etc)  and **submit the runned ipynb file. There are a total of 24 questions. **\n","\n","#### This program reads two dataset files called \"**A.csv**\" and \"**B.csv**\". You should store them in G-drive. You can stoe them in any folder of your choice or use the same folder hierarchy as shown inside this program. \n","\n","#### Since the file names used in this assignment is A.csv and B.csv, I used a new data frame name as in A1_DF, A2_DF, A3_DF, B1_DF, B2_DF, etc.\n","\n","#### If you have any questions on Spark, Colb, or this Assignment 2, contact my TA. If you see any ambiguity, please contact me or my TA.\n","\n","#### You have 2 weeks to complete this assignment."]},{"cell_type":"markdown","metadata":{"id":"QpAOoodb4teH"},"source":["# Run cells below to setup spark environment"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RPY2dYeNFjrg","executionInfo":{"status":"ok","timestamp":1621468677409,"user_tz":240,"elapsed":4668,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"05bd90b5-895a-4c18-9180-424b7840b9ec"},"source":["!pip install pyspark"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.1)\n","Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8ULwIGVhhsL2"},"source":["### Mounting this notebook with google drive \"/contesnt/gdrive/\" is the path to google drive\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Q0DuZp2F-MX","executionInfo":{"status":"ok","timestamp":1621468677410,"user_tz":240,"elapsed":4661,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"339eae7d-9553-4f90-ae14-c5fcec8b716f"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JBTuIlY5E3L6"},"source":["### Import necessary libararies\n","\n","\n","*   SparkSession is used to create spark dataframe\n","*   import functions as f then when you want to use function you just simply call it by \"f\" instead of typing the full word \"functions\"\n","* functions module contain many builtin function such as concatenate, add_date etc.\n","* UserDefinedFucntion is a module that allow you to create your on function  that will be applied to each entry of dataframe\n","\n"]},{"cell_type":"code","metadata":{"id":"VU8kC2nJTUdB"},"source":["from pyspark.sql import functions as f\n","from pyspark.sql.functions import UserDefinedFunction\n","from datetime import date, datetime, timedelta\n","from pyspark.sql.types import *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WXHUM8hdSI1s"},"source":["### Creating SparkSession object\n","Spark session objects can be created by using SparkSession.builder.getorCreated(). You also have to specify APP_NAME for your sparkSession that you want to work on.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":218},"id":"mAlndDJyDuag","executionInfo":{"status":"ok","timestamp":1621468686831,"user_tz":240,"elapsed":14070,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"06077864-addf-490a-c621-e8ecbccc4de2"},"source":["from pyspark.sql import SparkSession\n","APP_NAME = \"preprocessing\"\n","spark = SparkSession.builder.appName(APP_NAME).getOrCreate()\n","spark"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://6ef43b80bfd0:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>preprocessing</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7fbf6c486910>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"WpK-oETDSQhu"},"source":["### Creating a Dataframe from csv files\n","You can read csv files from google drive by providing the path “/gdrive/My Drive/”. This path is the path to access files in your google drive. Since we’ve put dataset in “data” folder, the path name should be “/gdrive/My Drive/data/filename.csv”\n","\n","You can create a spark dataframe by calling sparkSession object name “spark” that you have created in the previous step. \n","spark.read(‘csv’): specify that you want spark to read .csv file.\n","option(‘header’,’true’): contain header to the dataframe\n","option(‘inferSchema’, ‘true’): ensure that we detect the correct type for each column. Without this option, the default type will be string for all columns.\n"," printSchema to see the Schema of data\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AutTgo720TKc","executionInfo":{"status":"ok","timestamp":1621468695369,"user_tz":240,"elapsed":22600,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"51089d2a-2643-4fa4-86c2-49ac9a6a8b43"},"source":["#Create DF called train\n","#file_folder = './gdrive/My Drive/data/'\n","file_folder = \"./gdrive/My Drive/Covid19/data/\"\n","A_DF = spark.read.format('csv').option('header', 'true').option('inferSchema', 'true').load(file_folder + 'A.csv')\n","A_DF.show()\n","# null values in csv file is marked as \"null\" without quotes."],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------+--------------+----+----+----------+--------------+----------+\n","| Id|Province/State|Country/Region| Lat|Long|      Date|ConfirmedCases|Fatalities|\n","+---+--------------+--------------+----+----+----------+--------------+----------+\n","|  1|          null|   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|\n","|  2|          null|   Afghanistan|33.0|65.0|2020-01-23|           0.0|       0.0|\n","|  3|          null|   Afghanistan|33.0|65.0|2020-01-24|           0.0|       0.0|\n","|  4|          null|   Afghanistan|33.0|65.0|2020-01-25|           0.0|       0.0|\n","|  5|          null|   Afghanistan|33.0|65.0|2020-01-26|           0.0|       0.0|\n","|  6|          null|   Afghanistan|33.0|65.0|2020-01-27|           0.0|       0.0|\n","|  7|          null|   Afghanistan|33.0|65.0|2020-01-28|           0.0|       0.0|\n","|  8|          null|   Afghanistan|33.0|65.0|2020-01-29|           0.0|       0.0|\n","|  9|          null|   Afghanistan|33.0|65.0|2020-01-30|           0.0|       0.0|\n","| 10|          null|   Afghanistan|33.0|65.0|2020-01-31|           0.0|       0.0|\n","| 11|          null|   Afghanistan|33.0|65.0|2020-02-01|           0.0|       0.0|\n","| 12|          null|   Afghanistan|33.0|65.0|2020-02-02|           0.0|       0.0|\n","| 13|          null|   Afghanistan|33.0|65.0|2020-02-03|           0.0|       0.0|\n","| 14|          null|   Afghanistan|33.0|65.0|2020-02-04|           0.0|       0.0|\n","| 15|          null|   Afghanistan|33.0|65.0|2020-02-05|           0.0|       0.0|\n","| 16|          null|   Afghanistan|33.0|65.0|2020-02-06|           0.0|       0.0|\n","| 17|          null|   Afghanistan|33.0|65.0|2020-02-07|           0.0|       0.0|\n","| 18|          null|   Afghanistan|33.0|65.0|2020-02-08|           0.0|       0.0|\n","| 19|          null|   Afghanistan|33.0|65.0|2020-02-09|           0.0|       0.0|\n","| 20|          null|   Afghanistan|33.0|65.0|2020-02-10|           0.0|       0.0|\n","+---+--------------+--------------+----+----+----------+--------------+----------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gnNtv9D6VYUM"},"source":["### Rename Columns\n","We can rename columns of dataframe by directly calling command withColumnRenamed() from a data frame object. In this case “train” is a dataFrame object.\n","* withColumnRenamed(): to rename columns result in a new data frame because the dataframe consists of Row RDDs. They are immutable\n","* We have to assign it back to “train” (train = train.withColumnRenamed()) in order to modify the dataframe\n","* In order to see content in spark dataframe, the command .show() is called directly from a dataframe object\n","* .show() command will show the first 20 rows of the dataframe"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iAIVNUY7s8LW","executionInfo":{"status":"ok","timestamp":1621468696480,"user_tz":240,"elapsed":23703,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"81649ede-af5e-444c-e475-015152b60fb1"},"source":["# rename columns\n","A2_DF = A_DF.withColumnRenamed('Province/State','Province_State').withColumnRenamed('Country/Region','Country_Region')\n","A2_DF.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------+--------------+----+----+----------+--------------+----------+\n","| Id|Province_State|Country_Region| Lat|Long|      Date|ConfirmedCases|Fatalities|\n","+---+--------------+--------------+----+----+----------+--------------+----------+\n","|  1|          null|   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|\n","|  2|          null|   Afghanistan|33.0|65.0|2020-01-23|           0.0|       0.0|\n","|  3|          null|   Afghanistan|33.0|65.0|2020-01-24|           0.0|       0.0|\n","|  4|          null|   Afghanistan|33.0|65.0|2020-01-25|           0.0|       0.0|\n","|  5|          null|   Afghanistan|33.0|65.0|2020-01-26|           0.0|       0.0|\n","|  6|          null|   Afghanistan|33.0|65.0|2020-01-27|           0.0|       0.0|\n","|  7|          null|   Afghanistan|33.0|65.0|2020-01-28|           0.0|       0.0|\n","|  8|          null|   Afghanistan|33.0|65.0|2020-01-29|           0.0|       0.0|\n","|  9|          null|   Afghanistan|33.0|65.0|2020-01-30|           0.0|       0.0|\n","| 10|          null|   Afghanistan|33.0|65.0|2020-01-31|           0.0|       0.0|\n","| 11|          null|   Afghanistan|33.0|65.0|2020-02-01|           0.0|       0.0|\n","| 12|          null|   Afghanistan|33.0|65.0|2020-02-02|           0.0|       0.0|\n","| 13|          null|   Afghanistan|33.0|65.0|2020-02-03|           0.0|       0.0|\n","| 14|          null|   Afghanistan|33.0|65.0|2020-02-04|           0.0|       0.0|\n","| 15|          null|   Afghanistan|33.0|65.0|2020-02-05|           0.0|       0.0|\n","| 16|          null|   Afghanistan|33.0|65.0|2020-02-06|           0.0|       0.0|\n","| 17|          null|   Afghanistan|33.0|65.0|2020-02-07|           0.0|       0.0|\n","| 18|          null|   Afghanistan|33.0|65.0|2020-02-08|           0.0|       0.0|\n","| 19|          null|   Afghanistan|33.0|65.0|2020-02-09|           0.0|       0.0|\n","| 20|          null|   Afghanistan|33.0|65.0|2020-02-10|           0.0|       0.0|\n","+---+--------------+--------------+----+----+----------+--------------+----------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7s-759UA0rsT","executionInfo":{"status":"ok","timestamp":1621468696481,"user_tz":240,"elapsed":23697,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"a3ec4b2b-70d8-4a08-8d06-7863f1e6db60"},"source":["# crete two dataframes (ynames, cpd) that store some column names which will be used later\n","ynames = ['ConfirmedCases', 'Fatalities']\n","ny = len(ynames)\n","ny"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VaMXHWXFBwIV","executionInfo":{"status":"ok","timestamp":1621468696481,"user_tz":240,"elapsed":23690,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"d433eb13-d418-459f-8952-9fdc7c94f4a6"},"source":["cp = ['Country_Region','Province_State']\n","cpd = cp + ['Date']\n","cpd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Country_Region', 'Province_State', 'Date']"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_85k7eXtOu7x","executionInfo":{"status":"ok","timestamp":1621468696482,"user_tz":240,"elapsed":23684,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"842373dc-a7cb-46c5-dc43-3bd29483e35f"},"source":["#Q1 crete a new variable called geography that stores columns 'Lat' and 'Long', which will be used later and then run.\n","\n","geography = ['Lat', 'Long']\n","geography"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Lat', 'Long']"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"hE8tj5wHaOAi"},"source":["### Fill missing values with empty string\n","An example of filling missing value with empty string in \"Provinve_State\" column"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GSxutFf8aHdU","executionInfo":{"status":"ok","timestamp":1621468696717,"user_tz":240,"elapsed":23912,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"affb7129-1929-46d9-df09-d78af69e8f5d"},"source":["# filling missing values with empty string\n","A3_DF = A2_DF.fillna({'Province_State' : '' })\n","A3_DF.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------+--------------+----+----+----------+--------------+----------+\n","| Id|Province_State|Country_Region| Lat|Long|      Date|ConfirmedCases|Fatalities|\n","+---+--------------+--------------+----+----+----------+--------------+----------+\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|\n","|  2|              |   Afghanistan|33.0|65.0|2020-01-23|           0.0|       0.0|\n","|  3|              |   Afghanistan|33.0|65.0|2020-01-24|           0.0|       0.0|\n","|  4|              |   Afghanistan|33.0|65.0|2020-01-25|           0.0|       0.0|\n","|  5|              |   Afghanistan|33.0|65.0|2020-01-26|           0.0|       0.0|\n","|  6|              |   Afghanistan|33.0|65.0|2020-01-27|           0.0|       0.0|\n","|  7|              |   Afghanistan|33.0|65.0|2020-01-28|           0.0|       0.0|\n","|  8|              |   Afghanistan|33.0|65.0|2020-01-29|           0.0|       0.0|\n","|  9|              |   Afghanistan|33.0|65.0|2020-01-30|           0.0|       0.0|\n","| 10|              |   Afghanistan|33.0|65.0|2020-01-31|           0.0|       0.0|\n","| 11|              |   Afghanistan|33.0|65.0|2020-02-01|           0.0|       0.0|\n","| 12|              |   Afghanistan|33.0|65.0|2020-02-02|           0.0|       0.0|\n","| 13|              |   Afghanistan|33.0|65.0|2020-02-03|           0.0|       0.0|\n","| 14|              |   Afghanistan|33.0|65.0|2020-02-04|           0.0|       0.0|\n","| 15|              |   Afghanistan|33.0|65.0|2020-02-05|           0.0|       0.0|\n","| 16|              |   Afghanistan|33.0|65.0|2020-02-06|           0.0|       0.0|\n","| 17|              |   Afghanistan|33.0|65.0|2020-02-07|           0.0|       0.0|\n","| 18|              |   Afghanistan|33.0|65.0|2020-02-08|           0.0|       0.0|\n","| 19|              |   Afghanistan|33.0|65.0|2020-02-09|           0.0|       0.0|\n","| 20|              |   Afghanistan|33.0|65.0|2020-02-10|           0.0|       0.0|\n","+---+--------------+--------------+----+----+----------+--------------+----------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CRHXCFt0dhYS"},"source":["### Create new column from existing columns\n","* withColumn() can also create a new column as well\n","* by specify column name, if the column name doesn’t exist in the dataframe, it will automatically create a new column with the name\n","* In this case “key” is the column name. \n","* after that, build in function f.concat() is call to concat value in two columns with “_”\n","build in function f.lit() is necessary. It is use to pass a constant or value to operate with value in a dataframe i.e. in this case, “_’ is passed into f.lit() fiction in order to let it connect between two fields value\n","* For example, for a tuple “province_state = Busan”, “Country_regoin = South Korea” the result of will be “Busan_South Korea”\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKAK-sfLaUst","executionInfo":{"status":"ok","timestamp":1621468697314,"user_tz":240,"elapsed":24502,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"bae967b4-d5ce-4706-d8be-b101bd947b11"},"source":["# Example of creating a new column \"PSCR\" by concatinating two columns connected by \"_\"\n","#lit() PySpark SQL functions lit() and typedLit() are used to add a new column to DataFrame by assigning a literal or constant value. Both these functions return Column type as return type.\n","A4_DF = A3_DF.withColumn('PSCR',f.concat(f.col('Province_State'),f.lit('_'),f.col('Country_Region')))\n","A4_DF.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------+--------------+----+----+----------+--------------+----------+------------+\n","| Id|Province_State|Country_Region| Lat|Long|      Date|ConfirmedCases|Fatalities|        PSCR|\n","+---+--------------+--------------+----+----+----------+--------------+----------+------------+\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|\n","|  2|              |   Afghanistan|33.0|65.0|2020-01-23|           0.0|       0.0|_Afghanistan|\n","|  3|              |   Afghanistan|33.0|65.0|2020-01-24|           0.0|       0.0|_Afghanistan|\n","|  4|              |   Afghanistan|33.0|65.0|2020-01-25|           0.0|       0.0|_Afghanistan|\n","|  5|              |   Afghanistan|33.0|65.0|2020-01-26|           0.0|       0.0|_Afghanistan|\n","|  6|              |   Afghanistan|33.0|65.0|2020-01-27|           0.0|       0.0|_Afghanistan|\n","|  7|              |   Afghanistan|33.0|65.0|2020-01-28|           0.0|       0.0|_Afghanistan|\n","|  8|              |   Afghanistan|33.0|65.0|2020-01-29|           0.0|       0.0|_Afghanistan|\n","|  9|              |   Afghanistan|33.0|65.0|2020-01-30|           0.0|       0.0|_Afghanistan|\n","| 10|              |   Afghanistan|33.0|65.0|2020-01-31|           0.0|       0.0|_Afghanistan|\n","| 11|              |   Afghanistan|33.0|65.0|2020-02-01|           0.0|       0.0|_Afghanistan|\n","| 12|              |   Afghanistan|33.0|65.0|2020-02-02|           0.0|       0.0|_Afghanistan|\n","| 13|              |   Afghanistan|33.0|65.0|2020-02-03|           0.0|       0.0|_Afghanistan|\n","| 14|              |   Afghanistan|33.0|65.0|2020-02-04|           0.0|       0.0|_Afghanistan|\n","| 15|              |   Afghanistan|33.0|65.0|2020-02-05|           0.0|       0.0|_Afghanistan|\n","| 16|              |   Afghanistan|33.0|65.0|2020-02-06|           0.0|       0.0|_Afghanistan|\n","| 17|              |   Afghanistan|33.0|65.0|2020-02-07|           0.0|       0.0|_Afghanistan|\n","| 18|              |   Afghanistan|33.0|65.0|2020-02-08|           0.0|       0.0|_Afghanistan|\n","| 19|              |   Afghanistan|33.0|65.0|2020-02-09|           0.0|       0.0|_Afghanistan|\n","| 20|              |   Afghanistan|33.0|65.0|2020-02-10|           0.0|       0.0|_Afghanistan|\n","+---+--------------+--------------+----+----+----------+--------------+----------+------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3Kk5cPqoyhcg"},"source":["Repeat the same procedure for the dataset A (A.csv) to dataset B (B.csv)\n","rename columns\n","filling missing value empty string\n","modify existing column\n","f.concat() and f.lit()"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71brmmQVDVHe","executionInfo":{"status":"ok","timestamp":1621468698481,"user_tz":240,"elapsed":25662,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"74f826da-07ff-46aa-99a0-b6b54c4fc81c"},"source":["# In Q2, Q3, and Q4, you are basically repeating the same steps as you did for dataset A.csv file\n","#Q2 Read the dataset B.csv using the similar steps.\n","file_folder = \"./gdrive/My Drive/Covid19/data/\"\n","B_DF = spark.read.format('csv').option('header', 'true').option('inferSchema', 'true').load(file_folder + 'B.csv')\n","B_DF.show()\n","# rename columns as above \n","#Q3 #Rename columns 'Province/State' to 'Province_State' by calling command withColumnRenamed() from a dataframe\n","B2_DF = B_DF.withColumnRenamed('Province/State','Province_State').withColumnRenamed('Country/Region','Country_Region')\n","B2_DF.show()\n","\n","\n","#Q4 filling missing (null) values for 'Province_State' with empty string as done in the A.csv.\n","B3_DF = B2_DF.fillna({'Province_State' : '' })\n","B3_DF.show()\n","\n","\n","\n","\n","#Q5 create a new column \"PSRC\" by concatinating two columns as done in dataset A.csv\n","#You need to combine the Province_state and the country_region columns.\n","B4_DF = B3_DF.withColumn('PSCR',f.concat(f.col('Province_State'),f.lit('_'),f.col('Country_Region')))\n","B4_DF.show()\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+----------+--------------+--------------+----+----+----------+\n","|ForecastId|Province/State|Country/Region| Lat|Long|      Date|\n","+----------+--------------+--------------+----+----+----------+\n","|         1|          null|   Afghanistan|33.0|65.0|2020-03-12|\n","|         2|          null|   Afghanistan|33.0|65.0|2020-03-13|\n","|         3|          null|   Afghanistan|33.0|65.0|2020-03-14|\n","|         4|          null|   Afghanistan|33.0|65.0|2020-03-15|\n","|         5|          null|   Afghanistan|33.0|65.0|2020-03-16|\n","|         6|          null|   Afghanistan|33.0|65.0|2020-03-17|\n","|         7|          null|   Afghanistan|33.0|65.0|2020-03-18|\n","|         8|          null|   Afghanistan|33.0|65.0|2020-03-19|\n","|         9|          null|   Afghanistan|33.0|65.0|2020-03-20|\n","|        10|          null|   Afghanistan|33.0|65.0|2020-03-21|\n","|        11|          null|   Afghanistan|33.0|65.0|2020-03-22|\n","|        12|          null|   Afghanistan|33.0|65.0|2020-03-23|\n","|        13|          null|   Afghanistan|33.0|65.0|2020-03-24|\n","|        14|          null|   Afghanistan|33.0|65.0|2020-03-25|\n","|        15|          null|   Afghanistan|33.0|65.0|2020-03-26|\n","|        16|          null|   Afghanistan|33.0|65.0|2020-03-27|\n","|        17|          null|   Afghanistan|33.0|65.0|2020-03-28|\n","|        18|          null|   Afghanistan|33.0|65.0|2020-03-29|\n","|        19|          null|   Afghanistan|33.0|65.0|2020-03-30|\n","|        20|          null|   Afghanistan|33.0|65.0|2020-03-31|\n","+----------+--------------+--------------+----+----+----------+\n","only showing top 20 rows\n","\n","+----------+--------------+--------------+----+----+----------+\n","|ForecastId|Province_State|Country_Region| Lat|Long|      Date|\n","+----------+--------------+--------------+----+----+----------+\n","|         1|          null|   Afghanistan|33.0|65.0|2020-03-12|\n","|         2|          null|   Afghanistan|33.0|65.0|2020-03-13|\n","|         3|          null|   Afghanistan|33.0|65.0|2020-03-14|\n","|         4|          null|   Afghanistan|33.0|65.0|2020-03-15|\n","|         5|          null|   Afghanistan|33.0|65.0|2020-03-16|\n","|         6|          null|   Afghanistan|33.0|65.0|2020-03-17|\n","|         7|          null|   Afghanistan|33.0|65.0|2020-03-18|\n","|         8|          null|   Afghanistan|33.0|65.0|2020-03-19|\n","|         9|          null|   Afghanistan|33.0|65.0|2020-03-20|\n","|        10|          null|   Afghanistan|33.0|65.0|2020-03-21|\n","|        11|          null|   Afghanistan|33.0|65.0|2020-03-22|\n","|        12|          null|   Afghanistan|33.0|65.0|2020-03-23|\n","|        13|          null|   Afghanistan|33.0|65.0|2020-03-24|\n","|        14|          null|   Afghanistan|33.0|65.0|2020-03-25|\n","|        15|          null|   Afghanistan|33.0|65.0|2020-03-26|\n","|        16|          null|   Afghanistan|33.0|65.0|2020-03-27|\n","|        17|          null|   Afghanistan|33.0|65.0|2020-03-28|\n","|        18|          null|   Afghanistan|33.0|65.0|2020-03-29|\n","|        19|          null|   Afghanistan|33.0|65.0|2020-03-30|\n","|        20|          null|   Afghanistan|33.0|65.0|2020-03-31|\n","+----------+--------------+--------------+----+----+----------+\n","only showing top 20 rows\n","\n","+----------+--------------+--------------+----+----+----------+\n","|ForecastId|Province_State|Country_Region| Lat|Long|      Date|\n","+----------+--------------+--------------+----+----+----------+\n","|         1|              |   Afghanistan|33.0|65.0|2020-03-12|\n","|         2|              |   Afghanistan|33.0|65.0|2020-03-13|\n","|         3|              |   Afghanistan|33.0|65.0|2020-03-14|\n","|         4|              |   Afghanistan|33.0|65.0|2020-03-15|\n","|         5|              |   Afghanistan|33.0|65.0|2020-03-16|\n","|         6|              |   Afghanistan|33.0|65.0|2020-03-17|\n","|         7|              |   Afghanistan|33.0|65.0|2020-03-18|\n","|         8|              |   Afghanistan|33.0|65.0|2020-03-19|\n","|         9|              |   Afghanistan|33.0|65.0|2020-03-20|\n","|        10|              |   Afghanistan|33.0|65.0|2020-03-21|\n","|        11|              |   Afghanistan|33.0|65.0|2020-03-22|\n","|        12|              |   Afghanistan|33.0|65.0|2020-03-23|\n","|        13|              |   Afghanistan|33.0|65.0|2020-03-24|\n","|        14|              |   Afghanistan|33.0|65.0|2020-03-25|\n","|        15|              |   Afghanistan|33.0|65.0|2020-03-26|\n","|        16|              |   Afghanistan|33.0|65.0|2020-03-27|\n","|        17|              |   Afghanistan|33.0|65.0|2020-03-28|\n","|        18|              |   Afghanistan|33.0|65.0|2020-03-29|\n","|        19|              |   Afghanistan|33.0|65.0|2020-03-30|\n","|        20|              |   Afghanistan|33.0|65.0|2020-03-31|\n","+----------+--------------+--------------+----+----+----------+\n","only showing top 20 rows\n","\n","+----------+--------------+--------------+----+----+----------+------------+\n","|ForecastId|Province_State|Country_Region| Lat|Long|      Date|        PSCR|\n","+----------+--------------+--------------+----+----+----------+------------+\n","|         1|              |   Afghanistan|33.0|65.0|2020-03-12|_Afghanistan|\n","|         2|              |   Afghanistan|33.0|65.0|2020-03-13|_Afghanistan|\n","|         3|              |   Afghanistan|33.0|65.0|2020-03-14|_Afghanistan|\n","|         4|              |   Afghanistan|33.0|65.0|2020-03-15|_Afghanistan|\n","|         5|              |   Afghanistan|33.0|65.0|2020-03-16|_Afghanistan|\n","|         6|              |   Afghanistan|33.0|65.0|2020-03-17|_Afghanistan|\n","|         7|              |   Afghanistan|33.0|65.0|2020-03-18|_Afghanistan|\n","|         8|              |   Afghanistan|33.0|65.0|2020-03-19|_Afghanistan|\n","|         9|              |   Afghanistan|33.0|65.0|2020-03-20|_Afghanistan|\n","|        10|              |   Afghanistan|33.0|65.0|2020-03-21|_Afghanistan|\n","|        11|              |   Afghanistan|33.0|65.0|2020-03-22|_Afghanistan|\n","|        12|              |   Afghanistan|33.0|65.0|2020-03-23|_Afghanistan|\n","|        13|              |   Afghanistan|33.0|65.0|2020-03-24|_Afghanistan|\n","|        14|              |   Afghanistan|33.0|65.0|2020-03-25|_Afghanistan|\n","|        15|              |   Afghanistan|33.0|65.0|2020-03-26|_Afghanistan|\n","|        16|              |   Afghanistan|33.0|65.0|2020-03-27|_Afghanistan|\n","|        17|              |   Afghanistan|33.0|65.0|2020-03-28|_Afghanistan|\n","|        18|              |   Afghanistan|33.0|65.0|2020-03-29|_Afghanistan|\n","|        19|              |   Afghanistan|33.0|65.0|2020-03-30|_Afghanistan|\n","|        20|              |   Afghanistan|33.0|65.0|2020-03-31|_Afghanistan|\n","+----------+--------------+--------------+----+----+----------+------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"V4lCjk--hQtv"},"source":["### Aggreagte funtion (max)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MKucmUyUjHSs","executionInfo":{"status":"ok","timestamp":1621468699817,"user_tz":240,"elapsed":26991,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"0fb6e371-5c0c-48fe-d518-0ce9f0676493"},"source":["# tmax is the last day of training; Either syntax below is working\n","tmax = A4_DF.agg (f.max(A4_DF.Date)).show()\n","#tmax = train.agg({'Date':'max'}).show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+----------+\n","| max(Date)|\n","+----------+\n","|2020-03-24|\n","+----------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RL4qjDqKfeSh"},"source":["Collect (Action) - Return all the elements of the dataset as an array at the driver program. This is usually useful after a filter or other operation that returns a sufficiently small subset of the data.\n","\n","#collect()[0]: Row(max(Date)='2020-03-24')\n","\n","#collect(): [Row(max(Date)='2020-03-24')]"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"19AVJYTMe1LQ","executionInfo":{"status":"ok","timestamp":1621468700224,"user_tz":240,"elapsed":27390,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"67c6e788-8783-43b5-ef10-6a2b0a2637e4"},"source":["tmax = A4_DF.agg({'Date':'max'}).collect()[0]['max(Date)']\n","tmax"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2020-03-24'"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"YBET5nexfs6J"},"source":["Convert the string to a datetime object\n","print() \n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6WDhRgCbAAj","executionInfo":{"status":"ok","timestamp":1621468700224,"user_tz":240,"elapsed":27382,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"a6a82ddf-ea78-4307-89ac-6b6446b8762b"},"source":["print(type(tmax))\n","tmax = datetime.strptime(tmax, '%Y-%m-%d').date()\n","print(tmax,type(tmax))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'str'>\n","2020-03-24 <class 'datetime.date'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0hS8SjY0jLte"},"source":["The same example on the test data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4mrsAsmpjHE8","executionInfo":{"status":"ok","timestamp":1621468700952,"user_tz":240,"elapsed":28103,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"c9f7ae73-965f-4b06-cc94-266b48294de6"},"source":["# fmax is the last day of B dataset\n","#Q6 Find the last day from the B dataset using the max function.\n","fmax = B4_DF.agg (f.max(B4_DF.Date)).show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+----------+\n","| max(Date)|\n","+----------+\n","|2020-04-23|\n","+----------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"_BnGcKSvjXFz","executionInfo":{"status":"ok","timestamp":1621468700953,"user_tz":240,"elapsed":28096,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"597276de-0441-401f-92de-085fea4c9db2"},"source":["#Q7 Convert the above last day dataframe into a date string\n","fmax = B4_DF.agg({'Date':'max'}).collect()[0]['max(Date)']\n","fmax"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2020-04-23'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rGuKudG-jiwk","executionInfo":{"status":"ok","timestamp":1621468700954,"user_tz":240,"elapsed":28090,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"84023354-2fcf-4dba-871a-aaeef389dbff"},"source":["#Q8 Convert the date string o a datetime object\n","print(type(fmax))\n","fmax = datetime.strptime(fmax, '%Y-%m-%d').date()\n","print(fmax,type(fmax))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'str'>\n","2020-04-23 <class 'datetime.date'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I1hfe2JOrJYv"},"source":["An example of using min aggregate function and collect the value\n","\n","type(tmin) below is a string that is selected from the result of collect()[0]['min(Date)']\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NSDG4R62jG4T","executionInfo":{"status":"ok","timestamp":1621468701381,"user_tz":240,"elapsed":28510,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"479c24da-c924-44c6-cde8-faf35e9493d4"},"source":["tmin = A4_DF.agg({'Date':'min'}).collect()[0]['min(Date)']\n","fmin = B4_DF.agg({'Date':'min'}).collect()[0]['min(Date)']\n","#tmin,fmin\n","print(tmin)\n","print(fmin)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-01-22\n","2020-03-12\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cuIlv-rJlEcS","executionInfo":{"status":"ok","timestamp":1621468701907,"user_tz":240,"elapsed":29028,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"16353af6-0936-4f8a-96a5-e6ce7021d512"},"source":["#Q9 Convert both of the above computed strings to the datetime object\n","tmin = datetime.strptime(tmin, '%Y-%m-%d').date()\n","fmin = datetime.strptime(fmin, '%Y-%m-%d').date()\n","print(tmin,type(tmin))\n","print(fmin,type(fmin))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-01-22 <class 'datetime.date'>\n","2020-03-12 <class 'datetime.date'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9EHs0rNxvZ1h"},"source":["### Using SQL statement to exact column and merge dataframes\n","We can use SQL command in spark SQL by \n","* first using command creatieOrReplaceTempView(“viewname”) directly from a dataframe that you want to use SQL statement\n","* In this case, we create view name “train” from train dataframe\n","* view name “test” from test data frame\n","* We use command spark.sql(“SQL statement)\n","* The result is a new dataframe\n","* From example below first SQL statement is used to create a new dataframe from ‘test\n","* “SELECT Country_Region, Province_State, ForecastId, Date FROM test” the new dataframe from this query is assigned to “test_sub_col”\n","* then view name “sub_test” is created from test_sub_col dataframe\n","* then the last SQL statement is used to merge two view together e.g. “train” and “sub_test”\n","* the result is assigned to merge_train \n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zmDU18pAFq4I","executionInfo":{"status":"ok","timestamp":1621468703375,"user_tz":240,"elapsed":30489,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"8246c19f-5139-4601-cf75-c8bde8c82ba9"},"source":["# In order to execute a SQL command, you have to create a view of the dataframe first using createOrReplaceTempView()\n","# and use it inside spark.sql command\n","A4_DF.createOrReplaceTempView('A4_V')\n","A5_DF = spark.sql('select * from A4_V')\n","A5_DF.show(3)\n","A5_DF.count()\n","B4_DF.createOrReplaceTempView('B4_V')\n","B5_DF = spark.sql('select * from B4_V')\n","B5_DF.show(3)\n","B5_DF.count()\n","\n","B_sub_col_DF = spark.sql('SELECT Country_Region, Province_State, ForecastId, Date FROM B4_V')\n","B_sub_col_DF.show(3)\n","B_sub_col_DF.count()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------+--------------+----+----+----------+--------------+----------+------------+\n","| Id|Province_State|Country_Region| Lat|Long|      Date|ConfirmedCases|Fatalities|        PSCR|\n","+---+--------------+--------------+----+----+----------+--------------+----------+------------+\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|\n","|  2|              |   Afghanistan|33.0|65.0|2020-01-23|           0.0|       0.0|_Afghanistan|\n","|  3|              |   Afghanistan|33.0|65.0|2020-01-24|           0.0|       0.0|_Afghanistan|\n","+---+--------------+--------------+----+----+----------+--------------+----------+------------+\n","only showing top 3 rows\n","\n","+----------+--------------+--------------+----+----+----------+------------+\n","|ForecastId|Province_State|Country_Region| Lat|Long|      Date|        PSCR|\n","+----------+--------------+--------------+----+----+----------+------------+\n","|         1|              |   Afghanistan|33.0|65.0|2020-03-12|_Afghanistan|\n","|         2|              |   Afghanistan|33.0|65.0|2020-03-13|_Afghanistan|\n","|         3|              |   Afghanistan|33.0|65.0|2020-03-14|_Afghanistan|\n","+----------+--------------+--------------+----+----+----------+------------+\n","only showing top 3 rows\n","\n","+--------------+--------------+----------+----------+\n","|Country_Region|Province_State|ForecastId|      Date|\n","+--------------+--------------+----------+----------+\n","|   Afghanistan|              |         1|2020-03-12|\n","|   Afghanistan|              |         2|2020-03-13|\n","|   Afghanistan|              |         3|2020-03-14|\n","+--------------+--------------+----------+----------+\n","only showing top 3 rows\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["12212"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HQFhYUtnvuj9","executionInfo":{"status":"ok","timestamp":1621468703802,"user_tz":240,"elapsed":30910,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"47c1f92c-2e66-4840-cb07-fd1753793b1b"},"source":["#Q10. Use SQL SELECT command to store Country_Region, Date, ConfirmedCases, and Fatalities. Call the new dataframe \"CDCF_DF\". \n","CDCF_DF = spark.sql('SELECT Country_Region, Date, ConfirmedCases, Fatalities FROM A4_V')\n","#Q11 Show(20)\n","CDCF_DF.show(20)\n","#Q12, count the number of rows of \"CDCF_DF\" dataframe.\n","CDCF_DF.count()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+--------------+----------+--------------+----------+\n","|Country_Region|      Date|ConfirmedCases|Fatalities|\n","+--------------+----------+--------------+----------+\n","|   Afghanistan|2020-01-22|           0.0|       0.0|\n","|   Afghanistan|2020-01-23|           0.0|       0.0|\n","|   Afghanistan|2020-01-24|           0.0|       0.0|\n","|   Afghanistan|2020-01-25|           0.0|       0.0|\n","|   Afghanistan|2020-01-26|           0.0|       0.0|\n","|   Afghanistan|2020-01-27|           0.0|       0.0|\n","|   Afghanistan|2020-01-28|           0.0|       0.0|\n","|   Afghanistan|2020-01-29|           0.0|       0.0|\n","|   Afghanistan|2020-01-30|           0.0|       0.0|\n","|   Afghanistan|2020-01-31|           0.0|       0.0|\n","|   Afghanistan|2020-02-01|           0.0|       0.0|\n","|   Afghanistan|2020-02-02|           0.0|       0.0|\n","|   Afghanistan|2020-02-03|           0.0|       0.0|\n","|   Afghanistan|2020-02-04|           0.0|       0.0|\n","|   Afghanistan|2020-02-05|           0.0|       0.0|\n","|   Afghanistan|2020-02-06|           0.0|       0.0|\n","|   Afghanistan|2020-02-07|           0.0|       0.0|\n","|   Afghanistan|2020-02-08|           0.0|       0.0|\n","|   Afghanistan|2020-02-09|           0.0|       0.0|\n","|   Afghanistan|2020-02-10|           0.0|       0.0|\n","+--------------+----------+--------------+----------+\n","only showing top 20 rows\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["17892"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8p0bvkszRLmS","executionInfo":{"status":"ok","timestamp":1621468704635,"user_tz":240,"elapsed":31736,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"2e47afd8-cfca-4a82-e4e3-a7fd855a1275"},"source":["#Q13 Perform groupby() by columns \"Country_Region\" and \"Date\" and then show(20)\n","CDCF_DF.groupby('Country_Region', 'Date').count().show(20)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+--------------+----------+-----+\n","|Country_Region|      Date|count|\n","+--------------+----------+-----+\n","|       Albania|2020-02-05|    1|\n","|       Albania|2020-02-18|    1|\n","|       Algeria|2020-03-19|    1|\n","|       Andorra|2020-02-14|    1|\n","|         Aruba|2020-01-30|    1|\n","|        Canada|2020-01-22|   11|\n","|         Chile|2020-03-01|    1|\n","|       Croatia|2020-01-26|    1|\n","|       Croatia|2020-02-02|    1|\n","|       Denmark|2020-03-01|    2|\n","|       Finland|2020-02-03|    1|\n","|        France|2020-02-09|    8|\n","|        France|2020-03-19|    8|\n","|         Gabon|2020-03-12|    1|\n","|     Guatemala|2020-03-22|    1|\n","|      Guernsey|2020-01-26|    1|\n","|      Guernsey|2020-03-16|    1|\n","|      Honduras|2020-01-23|    1|\n","|          Iraq|2020-03-17|    1|\n","|         Italy|2020-02-21|    1|\n","+--------------+----------+-----+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbdnMGS3vQY6","executionInfo":{"status":"ok","timestamp":1621468704996,"user_tz":240,"elapsed":32090,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"ce48673f-9f4d-45a0-fd57-cf6805d5f2ad"},"source":["# We want to use unionByName() operation between A4 and B5. \n","#But in order to execute it, both dataframes must have the same number of columns and the same column names.\n","# So, check their schema and remove some column names and change a column name.\n","#Q14 show the schema of A4 dataframe\n","A4_DF.printSchema()\n","#Q15 Show the schema of B5 dataframe\n","B5_DF.printSchema()\n","#Q16 from A4 frame, drop two columns \"ConfirmedCases\" and \"Fatalitie\" and then show(5). Use a single command to drop both columns.\n","A5_DF = A4_DF.drop('ConfirmedCases').drop('Fatalities')\n","A5_DF.show(5)\n","#Q17 from B5, rename column called \"ForecastID\" into \"Id\" and then show(5).\n","B6_DF = B5_DF.withColumnRenamed('ForecastId','Id')\n","B6_DF.show(5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["root\n"," |-- Id: integer (nullable = true)\n"," |-- Province_State: string (nullable = false)\n"," |-- Country_Region: string (nullable = true)\n"," |-- Lat: double (nullable = true)\n"," |-- Long: double (nullable = true)\n"," |-- Date: string (nullable = true)\n"," |-- ConfirmedCases: double (nullable = true)\n"," |-- Fatalities: double (nullable = true)\n"," |-- PSCR: string (nullable = true)\n","\n","root\n"," |-- ForecastId: integer (nullable = true)\n"," |-- Province_State: string (nullable = false)\n"," |-- Country_Region: string (nullable = true)\n"," |-- Lat: double (nullable = true)\n"," |-- Long: double (nullable = true)\n"," |-- Date: string (nullable = true)\n"," |-- PSCR: string (nullable = true)\n","\n","+---+--------------+--------------+----+----+----------+------------+\n","| Id|Province_State|Country_Region| Lat|Long|      Date|        PSCR|\n","+---+--------------+--------------+----+----+----------+------------+\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|_Afghanistan|\n","|  2|              |   Afghanistan|33.0|65.0|2020-01-23|_Afghanistan|\n","|  3|              |   Afghanistan|33.0|65.0|2020-01-24|_Afghanistan|\n","|  4|              |   Afghanistan|33.0|65.0|2020-01-25|_Afghanistan|\n","|  5|              |   Afghanistan|33.0|65.0|2020-01-26|_Afghanistan|\n","+---+--------------+--------------+----+----+----------+------------+\n","only showing top 5 rows\n","\n","+---+--------------+--------------+----+----+----------+------------+\n","| Id|Province_State|Country_Region| Lat|Long|      Date|        PSCR|\n","+---+--------------+--------------+----+----+----------+------------+\n","|  1|              |   Afghanistan|33.0|65.0|2020-03-12|_Afghanistan|\n","|  2|              |   Afghanistan|33.0|65.0|2020-03-13|_Afghanistan|\n","|  3|              |   Afghanistan|33.0|65.0|2020-03-14|_Afghanistan|\n","|  4|              |   Afghanistan|33.0|65.0|2020-03-15|_Afghanistan|\n","|  5|              |   Afghanistan|33.0|65.0|2020-03-16|_Afghanistan|\n","+---+--------------+--------------+----+----+----------+------------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"irvlf-ZVvWVD","executionInfo":{"status":"ok","timestamp":1621468705875,"user_tz":240,"elapsed":32962,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"92e3204a-19cf-4323-8308-0de6d5f5d8b5"},"source":["#Q18 Perform unionByName() operation between A4 and B5 and call the result \"AB_unioned\" dataframe.\n","AB_unioned = A5_DF.unionByName(B6_DF)\n","#Q19 show(20) of \"AB_unioned\"\n","AB_unioned.show(20)\n","#Q20 count the number of rows of \"AB_unioned\"\n","AB_unioned.count()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------+--------------+----+----+----------+------------+\n","| Id|Province_State|Country_Region| Lat|Long|      Date|        PSCR|\n","+---+--------------+--------------+----+----+----------+------------+\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|_Afghanistan|\n","|  2|              |   Afghanistan|33.0|65.0|2020-01-23|_Afghanistan|\n","|  3|              |   Afghanistan|33.0|65.0|2020-01-24|_Afghanistan|\n","|  4|              |   Afghanistan|33.0|65.0|2020-01-25|_Afghanistan|\n","|  5|              |   Afghanistan|33.0|65.0|2020-01-26|_Afghanistan|\n","|  6|              |   Afghanistan|33.0|65.0|2020-01-27|_Afghanistan|\n","|  7|              |   Afghanistan|33.0|65.0|2020-01-28|_Afghanistan|\n","|  8|              |   Afghanistan|33.0|65.0|2020-01-29|_Afghanistan|\n","|  9|              |   Afghanistan|33.0|65.0|2020-01-30|_Afghanistan|\n","| 10|              |   Afghanistan|33.0|65.0|2020-01-31|_Afghanistan|\n","| 11|              |   Afghanistan|33.0|65.0|2020-02-01|_Afghanistan|\n","| 12|              |   Afghanistan|33.0|65.0|2020-02-02|_Afghanistan|\n","| 13|              |   Afghanistan|33.0|65.0|2020-02-03|_Afghanistan|\n","| 14|              |   Afghanistan|33.0|65.0|2020-02-04|_Afghanistan|\n","| 15|              |   Afghanistan|33.0|65.0|2020-02-05|_Afghanistan|\n","| 16|              |   Afghanistan|33.0|65.0|2020-02-06|_Afghanistan|\n","| 17|              |   Afghanistan|33.0|65.0|2020-02-07|_Afghanistan|\n","| 18|              |   Afghanistan|33.0|65.0|2020-02-08|_Afghanistan|\n","| 19|              |   Afghanistan|33.0|65.0|2020-02-09|_Afghanistan|\n","| 20|              |   Afghanistan|33.0|65.0|2020-02-10|_Afghanistan|\n","+---+--------------+--------------+----+----+----------+------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["30104"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXNgV1dVvbX9","executionInfo":{"status":"ok","timestamp":1621468711669,"user_tz":240,"elapsed":38749,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"cdd967a7-68d0-4a67-eca0-75c61861ba45"},"source":["#Q21 Perform left outer join between A4 and B5 and call it \"AB_joined and select only the columns from the A4 dataframe\"\n","B5_DF.createOrReplaceTempView('B5_V')\n","AB_joined = spark.sql('SELECT * FROM A4_V LEFT OUTER JOIN B5_V' )\n","#Q22 Show (20) of \"AB_joined\"\n","AB_joined.show(20)\n","#Q23 Count #rows of \"AB_joined\"\n","AB_joined.count()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------+--------------+----+----+----------+--------------+----------+------------+----------+--------------+--------------+----+----+----------+------------+\n","| Id|Province_State|Country_Region| Lat|Long|      Date|ConfirmedCases|Fatalities|        PSCR|ForecastId|Province_State|Country_Region| Lat|Long|      Date|        PSCR|\n","+---+--------------+--------------+----+----+----------+--------------+----------+------------+----------+--------------+--------------+----+----+----------+------------+\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|         1|              |   Afghanistan|33.0|65.0|2020-03-12|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|         2|              |   Afghanistan|33.0|65.0|2020-03-13|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|         3|              |   Afghanistan|33.0|65.0|2020-03-14|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|         4|              |   Afghanistan|33.0|65.0|2020-03-15|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|         5|              |   Afghanistan|33.0|65.0|2020-03-16|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|         6|              |   Afghanistan|33.0|65.0|2020-03-17|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|         7|              |   Afghanistan|33.0|65.0|2020-03-18|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|         8|              |   Afghanistan|33.0|65.0|2020-03-19|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|         9|              |   Afghanistan|33.0|65.0|2020-03-20|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|        10|              |   Afghanistan|33.0|65.0|2020-03-21|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|        11|              |   Afghanistan|33.0|65.0|2020-03-22|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|        12|              |   Afghanistan|33.0|65.0|2020-03-23|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|        13|              |   Afghanistan|33.0|65.0|2020-03-24|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|        14|              |   Afghanistan|33.0|65.0|2020-03-25|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|        15|              |   Afghanistan|33.0|65.0|2020-03-26|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|        16|              |   Afghanistan|33.0|65.0|2020-03-27|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|        17|              |   Afghanistan|33.0|65.0|2020-03-28|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|        18|              |   Afghanistan|33.0|65.0|2020-03-29|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|        19|              |   Afghanistan|33.0|65.0|2020-03-30|_Afghanistan|\n","|  1|              |   Afghanistan|33.0|65.0|2020-01-22|           0.0|       0.0|_Afghanistan|        20|              |   Afghanistan|33.0|65.0|2020-03-31|_Afghanistan|\n","+---+--------------+--------------+----+----+----------+--------------+----------+------------+----------+--------------+--------------+----+----+----------+------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["218497104"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qegj88mUDLj_","executionInfo":{"status":"ok","timestamp":1621468713818,"user_tz":240,"elapsed":40886,"user":{"displayName":"Yiyun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHHU7PrGLYz-yThrTFqGwYryQ3cvybJgTC2WOftA=s64","userId":"11418697320007205677"}},"outputId":"b8959cb4-1f30-4736-dade-58aaf45b87d3"},"source":["#Q24 Save \"AB_unioned\" into a csv file in your disk and then show all the file names in the same folder you just saved.\n","import os\n","AB_unioned.write.save(file_folder + 'AB_unioned.csv')\n","os.listdir(file_folder)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['B.csv', 'A.csv', 'AB_unioned.csv']"]},"metadata":{"tags":[]},"execution_count":27}]}]}