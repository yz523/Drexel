{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab6.ipynb","provenance":[],"authorship_tag":"ABX9TyPfcCuXkXOtJb+8HHLofS5k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"bf_l-J6Qkfvy"},"source":["# Lab 6 Group 9\n","## Michael Karaman, Alexys Lamkin, Yiyun Zhang"]},{"cell_type":"markdown","metadata":{"id":"Z50PkRCakbK1"},"source":["### Exercise 1\n","\n","In the \"Combining Individual Probabilities\" section of the \"Naive Bayes Spam Filtering\" Wikipedia page, the author lists the following equation to use when considering multiple words for classification, assuming independence between each word:\n","\n","$p = \\frac{p_1p_2 \\ldots p_N}{p_1p_2 \\ldots p-N + (1-p_1)(1-p_2) \\ldots (1-p_N)}$\n","\n","where:\n","*   $p$ is the probability that an email is spam\n","*   $p_{n \\in N}$ is the probability $p(S|W_{n \\in N})$ i.e., an email is spam email knowing it contains word $n$ (where $N$ is the total number of words in the email)\n","\n","Not only is the author's description poorly-worded, the equation listed is also incorrect. When considering multiple independent events, each conditional probabilitiy would be multipled such that:\n","\n","$P(W_1, W_2, \\ldots, W_N|S) \\approx P(W_1|S) \\times P(W_2|S) \\times \\ldots \\times P(W_N|S) $\n","\n","Using the correct condititonal probability given independent events, the author's equation should've been:\n","\n","$P(S|W_1, W_2, \\ldots, W_N) = \\frac{P(W_1, W_2, \\ldots, W_N|S)P(S)}{P(W_1, W_2, \\ldots, W_N|S)P(S) + P(W_1, W_2, \\ldots, W_N|S)P(H)}$\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ghxj6OQNkVGJ"},"source":["### Exercise 2\n","$P(S|B,C)=\\frac{P(B,C|S)P(S)}{P(B,C|S)P(S)+P(B,C|H)P(H)}=\\frac{\\frac{12}{1}}{\\frac{12}{1}+\\frac{2}{3}}\\approx0.95$ \\\n","It is larger than both $P(S|B)=80\\%$ and $P(S|,B,C,W)=90\\%$, which means emails containing BUY and CHEAP are more likely to be spam."]},{"cell_type":"markdown","metadata":{"id":"G7qomit2kHlt"},"source":["### Exercise 3\n","\n","Classification problems can be generalized as using a categorization function $c(x)$ to categorize an instance $x$ (which exists in the domain $X$) within range $C$. Examples of categories $C$ includes \"spam\" and \"topics\" and examples of instances within such categories include \"spam\" and \"ham\" or \"finance\" and \"sports\", respectively. \n","\n","The Bayesian theorem is a method for solving classification problems. The theorem uses a prior probability for each category given no informtion about each instance and produces a posterior probability distribution over all the possible categories given each instance. \n","\n","The Maximum a posteriori (MAP) hypothesis can be used to simplify the Bayesian calculation by eliminating the need to calculate $P(x)$ and as a result, the final probability will not need to be normalized. \n","\n","The Naive Bayes Classifier can be derived in two steps:\n","1.   Assume that an instance $X$ can be described by a n-dimensonal vector of attributes\n","2.   Assume independence between instances (i.e., the conditional independence assumption) \n","\n","The slides provide an example of a classification problem where we're trying to determine if someone has the flu given specific symptoms (e.g., runny nose, cough, etc). When using the maximun likelihood for Naive Bayes approach, an issue arises where probabilities equal to zero overwhelm all other evidence leading to poor classification. To help mitigate the effects of zero probabilities, Laplace Smoothing can be used.\n","\n","The lectures also discusses a Naive Bayes classifier for multinomial variables. In this classifier, the order of words doesn't matter when calculating the probability. When training the classifiers, the vocabulary needs to be extracted from the training corpus and the probabilities for each unique word needs to be calculated. Again, to lessen the effects of zero probabilities, Laplace smoothing must be done. \n","\n","Naive Bayes classifiers are known to be dependenable, optimal (i.e., if the independence assumption holds) and fast. They are also known to have low storage requirements. \n","\n","To prevent underflow when calculating Naive Bayes probabilies, one can perform all computations by summing the logs of the probabilites instead of multiplying the probabilities. \n"]},{"cell_type":"markdown","metadata":{"id":"2LvovYR2kA7R"},"source":["### Exercise 4\n","\n","The examples below are from: https://www.exxactcorp.com/blog/Deep-Learning/the-benefits-examples-of-using-apache-spark-with-pyspark"]},{"cell_type":"code","metadata":{"id":"lDeD6TjWiXah","executionInfo":{"status":"ok","timestamp":1629848852649,"user_tz":240,"elapsed":3959,"user":{"displayName":"Alexys Onyemakonor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcy-rinLlnxJ70YfkeHSMhbO6hdAcHjM12DX6Q=s64","userId":"15627062774810642330"}}},"source":["#installing pyspark\n","!pip install -q pyspark"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LgN0E_3ifLJc","executionInfo":{"status":"ok","timestamp":1629849320970,"user_tz":240,"elapsed":1790,"user":{"displayName":"Alexys Onyemakonor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcy-rinLlnxJ70YfkeHSMhbO6hdAcHjM12DX6Q=s64","userId":"15627062774810642330"}},"outputId":"33ec7518-5dcb-43d3-9d9a-e13b72aee6df"},"source":["from pyspark import SparkContext\n","import numpy as np\n","\n","#initiate a spark session using 4 cores\n","sc=SparkContext(master=\"local[4]\")\n","\n","#create an array of 20 random #s\n","lst=np.random.randint(0,10,20)\n","\n","#create an RRD\n","A=sc.parallelize(lst)\n","\n","#verifying the # of distributee partitions (should match # of cores)\n","A.glom().collect()"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[4, 0, 5, 8, 6], [2, 3, 1, 1, 4], [7, 5, 0, 2, 0], [7, 3, 5, 0, 4]]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"qQET-t8ke3Hy","colab":{"base_uri":"https://localhost:8080/","height":37},"executionInfo":{"status":"ok","timestamp":1629849400481,"user_tz":240,"elapsed":266,"user":{"displayName":"Alexys Onyemakonor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcy-rinLlnxJ70YfkeHSMhbO6hdAcHjM12DX6Q=s64","userId":"15627062774810642330"}},"outputId":"bc54a304-4ae8-45c8-edc2-322145f88d0f"},"source":["#example: find the longest word\n","words = 'These are some of the best Macintosh computers ever'.split(' ')\n","wordRDD = sc.parallelize(words)\n","wordRDD.reduce(lambda w,v: w if len(w)>len(v) else v)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'computers'"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wVH8tofrjCRj","executionInfo":{"status":"ok","timestamp":1629849546267,"user_tz":240,"elapsed":277,"user":{"displayName":"Alexys Onyemakonor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcy-rinLlnxJ70YfkeHSMhbO6hdAcHjM12DX6Q=s64","userId":"15627062774810642330"}},"outputId":"e8ba1041-d7b4-4027-a516-edda2f185b46"},"source":["#example: compute squares\n","squares=A.map(lambda x:x*x)\n","squares.collect()"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[16, 0, 25, 64, 36, 4, 9, 1, 1, 16, 49, 25, 0, 4, 0, 49, 9, 25, 0, 16]"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"EDHymQ6Vj3Q7","executionInfo":{"status":"ok","timestamp":1629849638403,"user_tz":240,"elapsed":1149,"user":{"displayName":"Alexys Onyemakonor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcy-rinLlnxJ70YfkeHSMhbO6hdAcHjM12DX6Q=s64","userId":"15627062774810642330"}}},"source":["#stop spark session\n","sc.stop()"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Aw0og1ydnWH5"},"source":["The examples below are from: https://spark.apache.org/docs/latest/api/python/getting_started/quickstart.html"]},{"cell_type":"code","metadata":{"id":"waO0-NMZnFMb","executionInfo":{"status":"ok","timestamp":1629849674668,"user_tz":240,"elapsed":517,"user":{"displayName":"Alexys Onyemakonor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcy-rinLlnxJ70YfkeHSMhbO6hdAcHjM12DX6Q=s64","userId":"15627062774810642330"}}},"source":["from pyspark.sql import SparkSession\n","\n","#initiate PySpark session\n","spark = SparkSession.builder.getOrCreate()"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113},"id":"Gnh2F-u0m903","executionInfo":{"status":"ok","timestamp":1629850047294,"user_tz":240,"elapsed":1110,"user":{"displayName":"Alexys Onyemakonor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcy-rinLlnxJ70YfkeHSMhbO6hdAcHjM12DX6Q=s64","userId":"15627062774810642330"}},"outputId":"52b47e35-5bea-41c1-98c8-6c65f873581c"},"source":["from datetime import datetime, date\n","import pandas as pd\n","from pyspark.sql import Row\n","\n","#creating a PySpark dataframe from a pandas dataframe\n","pandas_df = pd.DataFrame({\n","    'a': [1, 2, 3],\n","    'b': [2., 3., 4.],\n","    'c': ['string1', 'string2', 'string3'],\n","    'd': [date(2000, 1, 1), date(2000, 2, 1), date(2000, 3, 1)],\n","    'e': [datetime(2000, 1, 1, 12, 0), datetime(2000, 1, 2, 12, 0), datetime(2000, 1, 3, 12, 0)]\n","})\n","\n","df = spark.createDataFrame(pandas_df)\n","\n","#viewing the dataframe\n","spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n","df"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table border='1'>\n","<tr><th>a</th><th>b</th><th>c</th><th>d</th><th>e</th></tr>\n","<tr><td>1</td><td>2.0</td><td>string1</td><td>2000-01-01</td><td>2000-01-01 12:00:00</td></tr>\n","<tr><td>2</td><td>3.0</td><td>string2</td><td>2000-02-01</td><td>2000-01-02 12:00:00</td></tr>\n","<tr><td>3</td><td>4.0</td><td>string3</td><td>2000-03-01</td><td>2000-01-03 12:00:00</td></tr>\n","</table>\n"],"text/plain":["+---+---+-------+----------+-------------------+\n","|  a|  b|      c|         d|                  e|\n","+---+---+-------+----------+-------------------+\n","|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n","|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n","|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n","+---+---+-------+----------+-------------------+"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v4jFw2WKoGwt","executionInfo":{"status":"ok","timestamp":1629850051185,"user_tz":240,"elapsed":739,"user":{"displayName":"Alexys Onyemakonor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcy-rinLlnxJ70YfkeHSMhbO6hdAcHjM12DX6Q=s64","userId":"15627062774810642330"}},"outputId":"e24df674-be3f-490d-9f6f-761e411df769"},"source":["#showing the summary of the dataframe\n","df.select(\"a\", \"b\", \"c\").describe().show()"],"execution_count":33,"outputs":[{"output_type":"stream","text":["+-------+---+---+-------+\n","|summary|  a|  b|      c|\n","+-------+---+---+-------+\n","|  count|  3|  3|      3|\n","|   mean|2.0|3.0|   null|\n","| stddev|1.0|1.0|   null|\n","|    min|  1|2.0|string1|\n","|    max|  3|4.0|string3|\n","+-------+---+---+-------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gN7etec5oP36","executionInfo":{"status":"ok","timestamp":1629850087481,"user_tz":240,"elapsed":288,"user":{"displayName":"Alexys Onyemakonor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcy-rinLlnxJ70YfkeHSMhbO6hdAcHjM12DX6Q=s64","userId":"15627062774810642330"}},"outputId":"7cfd3810-cc39-45ce-bf02-9112d1c142d3"},"source":["#collect the distributed data\n","df.collect()"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(a=1, b=2.0, c='string1', d=datetime.date(2000, 1, 1), e=datetime.datetime(2000, 1, 1, 12, 0)),\n"," Row(a=2, b=3.0, c='string2', d=datetime.date(2000, 2, 1), e=datetime.datetime(2000, 1, 2, 12, 0)),\n"," Row(a=3, b=4.0, c='string3', d=datetime.date(2000, 3, 1), e=datetime.datetime(2000, 1, 3, 12, 0))]"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bnfDqbF3o4N9","executionInfo":{"status":"ok","timestamp":1629850334981,"user_tz":240,"elapsed":1017,"user":{"displayName":"Alexys Onyemakonor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcy-rinLlnxJ70YfkeHSMhbO6hdAcHjM12DX6Q=s64","userId":"15627062774810642330"}},"outputId":"ccceb532-075f-444c-c99e-227a2d912a83"},"source":["#filtering dataframe (where a = 3)\n","from pyspark.sql.functions import pandas_udf\n","\n","def pandas_filter_func(iterator):\n","    for pandas_df in iterator:\n","        yield pandas_df[pandas_df.a == 3]\n","\n","df.mapInPandas(pandas_filter_func, schema=df.schema).show()"],"execution_count":37,"outputs":[{"output_type":"stream","text":["+---+---+-------+----------+-------------------+\n","|  a|  b|      c|         d|                  e|\n","+---+---+-------+----------+-------------------+\n","|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n","+---+---+-------+----------+-------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttqh20RepHZF","executionInfo":{"status":"ok","timestamp":1629850242848,"user_tz":240,"elapsed":4529,"user":{"displayName":"Alexys Onyemakonor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcy-rinLlnxJ70YfkeHSMhbO6hdAcHjM12DX6Q=s64","userId":"15627062774810642330"}},"outputId":"ed89e424-23d0-40cd-dfe1-e5a4ceb0f481"},"source":["#grouping data\n","df2 = spark.createDataFrame([\n","    ['red', 'banana', 1, 10], ['blue', 'banana', 2, 20], ['red', 'carrot', 3, 30],\n","    ['blue', 'grape', 4, 40], ['red', 'carrot', 5, 50], ['black', 'carrot', 6, 60],\n","    ['red', 'banana', 7, 70], ['red', 'grape', 8, 80]], schema=['color', 'fruit', 'v1', 'v2'])\n","\n","df2.groupby('color').avg().show()"],"execution_count":36,"outputs":[{"output_type":"stream","text":["+-----+-------+-------+\n","|color|avg(v1)|avg(v2)|\n","+-----+-------+-------+\n","|  red|    4.8|   48.0|\n","|black|    6.0|   60.0|\n","| blue|    3.0|   30.0|\n","+-----+-------+-------+\n","\n"],"name":"stdout"}]}]}